# Gemini Demo

## Leveraging Google's Gemini AI with Flutter: A Hands-on Exploration
This project serves as a comprehensive demonstration of integrating Google's cutting-edge Gemini AI capabilities within a Flutter application. Notably, it achieves this feat without relying on any external libraries or plugins. Instead, it leverages the raw power of Google's REST APIs, providing a deeper understanding of the underlying communication mechanisms.

The project utilizes the Gemini 1.5 Flash Model, enabling it to perform two distinct categories of tasks:

## Features
- **Image Recognition (Text and Image Input):**
  - This functionality empowers you to harness the combined power of text-based prompts and image inputs for vision-related tasks. Imagine sending an image alongside a descriptive prompt to the Gemini model. The model can then perform actions like generating captions or identifying objects within the image.

- **Text Generation (Text-only Input):**
  - The Gemini API demonstrates its versatility by also catering to text-only input scenarios. This feature unlocks the potential of natural language processing (NLP) tasks, such as text completion or summarization. Interestingly, the project even allows for chaining these text generation capabilities together, potentially leading to even more creative and informative outputs.

## Note
Due to the lack of a MacOS System, I haven't tested this project on any iOS device.

## Documentation
- Gemini API Overview: https://ai.google.dev/gemini-api/docs/api-overview
- Text and image input: https://ai.google.dev/gemini-api/docs/api-overview#text_image_input
- Text only input: https://ai.google.dev/gemini-api/docs/api-overview#text_input

## Preview
![alt text](https://i.postimg.cc/rsM08RRy/imgonline-com-ua-twotoone-ivg-VAq4-XXz-Wf19.png "img")
